{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generalizing-gradient-descent.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/grokking-deep-learning/blob/5-generalizing-gradient-descent/generalizing_gradient_descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I908rvvroG-6",
        "colab_type": "text"
      },
      "source": [
        "# learning multiple weights at a time: generalizing gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvrYi4GFoJ1X",
        "colab_type": "text"
      },
      "source": [
        "## Gradient descent learning with multiple inputs\n",
        "**Gradient descent also works with multiple inputs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85Ddmk57oO12",
        "colab_type": "text"
      },
      "source": [
        "We’ll more or less reveal how the same techniques can be used to update a\n",
        "network that contains multiple weights. Let’s start by jumping in the deep end, shall we?\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/gradient-descent-multiple-inputs-1.JPG?raw=1' width='800'/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Sz8zWj9ovH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def w_sum(a, b):\n",
        "  assert(len(a) == len(b))\n",
        "\n",
        "  output = 0\n",
        "  for i in range(len(a)):\n",
        "    output += (a[i] * b[i])\n",
        "  return output\n",
        "\n",
        "weights = [0.1, 0.2, -0.1]\n",
        "\n",
        "def neural_network(input, weights):\n",
        "  pred = w_sum(input, weights)\n",
        "  return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12GX4ZkxphIk",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/rahiakela/img-repo/blob/master/gradient-descent-multiple-inputs-2.JPG?raw=1' width='800'/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr2Va4Ulpb70",
        "colab_type": "code",
        "outputId": "2bbd482b-9ec1-4aa5-9b10-c7964fc82cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "toes = [8.5 , 9.5, 9.9, 9.0]\n",
        "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
        "nfans = [1.2 , 1.3, 0.5, 1.0]\n",
        "\n",
        "win_or_lose_binary = [1, 1, 0, 1]\n",
        "true = win_or_lose_binary[0]\n",
        "\n",
        "input = [toes[0], wlrec[0], nfans[0]]\n",
        "\n",
        "pred = neural_network(input, weights)\n",
        "print(f'Prediction: {str(pred)}')\n",
        "\n",
        "error = (pred - true) ** 2\n",
        "print(f'Error: {str(error)}')\n",
        "\n",
        "delta = pred - true\n",
        "print(f'Delta: {str(delta)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: 0.8600000000000001\n",
            "Error: 0.01959999999999997\n",
            "Delta: -0.1399999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY0qCdcRqsZy",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/rahiakela/img-repo/blob/master/gradient-descent-multiple-inputs-3.JPG?raw=1' width='800'/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL_iCSf5qV4b",
        "colab_type": "code",
        "outputId": "4a9cecc2-3b7d-4de4-d590-38698f6d2b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "def ele_mul(number, vector):\n",
        "  output = [0, 0, 0]\n",
        "\n",
        "  assert(len(output) == len(vector))\n",
        "\n",
        "  for i in range(len(vector)):\n",
        "    output[i] = number * vector[i]\n",
        "\n",
        "  return output\n",
        "\n",
        "input = [toes[0], wlrec[0], nfans[0]]\n",
        "\n",
        "pred = neural_network(input, weights)\n",
        "print(f'Prediction: {str(pred)}')\n",
        "\n",
        "error = (pred - true) ** 2\n",
        "print(f'Error: {str(error)}')\n",
        "\n",
        "delta = pred - true\n",
        "print(f'Delta: {str(delta)}')\n",
        "\n",
        "weight_deltas = ele_mul(delta, input)\n",
        "for wd in weight_deltas:\n",
        "  print(f'Weight Delta: {str(wd)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: 0.8600000000000001\n",
            "Error: 0.01959999999999997\n",
            "Delta: -0.1399999999999999\n",
            "Weight Delta: -1.189999999999999\n",
            "Weight Delta: -0.09099999999999994\n",
            "Weight Delta: -0.16799999999999987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cevlWPUGsQzK",
        "colab_type": "text"
      },
      "source": [
        "There’s nothing new in this diagram. Each weight_delta is calculated by taking its output\n",
        "delta and multiplying it by its input. In this case, because the three weights share the same\n",
        "output node, they also share that node’s delta. But the weights have different weight deltas\n",
        "owing to their different input values. Notice further that you can reuse the ele_mul function\n",
        "from before, because you’re multiplying each value in weights by the same value delta.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/gradient-descent-multiple-inputs-4.JPG?raw=1' width='800'/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnfSc0zYrokw",
        "colab_type": "code",
        "outputId": "1e521233-54e8-4f95-af06-3973a91c1b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "input = [toes[0], wlrec[0], nfans[0]]\n",
        "\n",
        "pred = neural_network(input, weights)\n",
        "\n",
        "error = (pred - true) ** 2\n",
        "\n",
        "delta = pred - true\n",
        "\n",
        "weight_deltas = ele_mul(delta, input)\n",
        "\n",
        "alpha = 0.01\n",
        "\n",
        "for i in range(len(weights)):\n",
        "  weights[i] -= alpha * weight_deltas[i]\n",
        "print(f'Weights: {str(weights)}')\n",
        "print(f'Weight Deltas: {str(weight_deltas)}')  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights: [0.1119, 0.20091, -0.09832]\n",
            "Weight Deltas: [-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7Jx3Te5_jJE",
        "colab_type": "text"
      },
      "source": [
        "## Let’s watch several steps of learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODBtQz78tFKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "d1922cc2-304f-44f1-c6ae-181d16224c12"
      },
      "source": [
        "def neural_network(input, weights):\n",
        "  output = 0\n",
        "  for i in range(len(input)):\n",
        "    output += (input[i] * weights[i])\n",
        "  return output\n",
        "\n",
        "def ele_mul(scalar, vector):\n",
        "  output = [0, 0, 0]\n",
        "  for i in range(len(output)):\n",
        "    output[i] = vector[i] * scalar\n",
        "  return output\n",
        "\n",
        "toes = [8.5 , 9.5, 9.9, 9.0]\n",
        "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
        "nfans = [1.2 , 1.3, 0.5, 1.0]     \n",
        "\n",
        "win_or_lose_binary = [1, 1, 0, 1]\n",
        "true = win_or_lose_binary[0]\n",
        "\n",
        "alpha = 0.01\n",
        "weights = [0.1, 0.2, -.1]\n",
        "input = [toes[0], wlrec[0], nfans[0]]\n",
        "\n",
        "for iter in range(3):\n",
        "  pred = neural_network(input, weights)\n",
        "\n",
        "  error = (pred - true) ** 2\n",
        "  delta = pred - true\n",
        "\n",
        "  weight_deltas = ele_mul(delta, input)\n",
        "\n",
        "  print(f'Iteration: {str(iter + 1)}')\n",
        "  print(f'Prediction: {str(pred)}')\n",
        "  print(f'Error: {str(error)}')\n",
        "  print(f'Delta: {str(delta)}')\n",
        "  print(f'Weights: {str(weights)}')\n",
        "  print(f'Weight_Deltas:')\n",
        "  print(str(weight_deltas))\n",
        "  print()\n",
        "\n",
        "for i in range(len(weights)):\n",
        "  weights[i] -= alpha * weight_deltas[i]  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1\n",
            "Prediction: 0.8600000000000001\n",
            "Error: 0.01959999999999997\n",
            "Delta: -0.1399999999999999\n",
            "Weights: [0.1, 0.2, -0.1]\n",
            "Weight_Deltas:\n",
            "[-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n",
            "\n",
            "Iteration: 2\n",
            "Prediction: 0.8600000000000001\n",
            "Error: 0.01959999999999997\n",
            "Delta: -0.1399999999999999\n",
            "Weights: [0.1, 0.2, -0.1]\n",
            "Weight_Deltas:\n",
            "[-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n",
            "\n",
            "Iteration: 3\n",
            "Prediction: 0.8600000000000001\n",
            "Error: 0.01959999999999997\n",
            "Delta: -0.1399999999999999\n",
            "Weights: [0.1, 0.2, -0.1]\n",
            "Weight_Deltas:\n",
            "[-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOwjq4rtEz2y",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/rahiakela/img-repo/blob/master/grokking-deep-learning/iteration-1.JPG?raw=1' width='800'/>\n",
        "\n",
        "We can make three individual error/weight curves, one for each weight. As before, the slopes\n",
        "of these curves (the dotted lines) are reflected by the weight_delta values. Notice that **a** is\n",
        "steeper than the others. Why is weight_delta steeper for **a** than the others if they share the\n",
        "same output delta and error measure? Because **a** has an input value that’s significantly\n",
        "higher than the others and thus, a higher derivative.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/grokking-deep-learning/iteration-2.JPG?raw=1' width='800'/>\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/grokking-deep-learning/iteration-3.JPG?raw=1' width='800'/>\n",
        "\n",
        "Most of the learning (weight changing) was performed\n",
        "on the weight with the largest input **a** , because the input changes the slope significantly.\n",
        "This isn’t necessarily advantageous in all settings. A subfield called normalization helps\n",
        "encourage learning across all weights despite dataset characteristics such as this. This\n",
        "significant difference in slope forced me to set alpha lower than I wanted (0.01 instead of\n",
        "0.1). Try setting alpha to 0.1: do you see how **a**a causes it to diverge?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YKezjBPG_fB",
        "colab_type": "text"
      },
      "source": [
        "## Freezing one weight: What does it do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM07AKvLHBSm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkNt4VRGEf6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}